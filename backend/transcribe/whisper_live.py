import os
import json
import requests
import time
import wave
import pyaudio
import threading
import numpy as np
from datetime import datetime
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®å‚æ•°
API_KEY = os.getenv("OPENAI_API_KEY")
print(API_KEY)
API_KEY = "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"
if not API_KEY:
    raise ValueError("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®OPENAI_API_KEY")

SAMPLE_RATE = 16000  # Whisperè¦æ±‚çš„é‡‡æ ·ç‡ u
CHUNK_SIZE = 1024  # æ¯æ¬¡è¯»å–çš„éŸ³é¢‘å—å¤§å°
SEGMENT_DURATION = 5.0  # æ¯5ç§’è‡ªåŠ¨æäº¤ä¸€æ¬¡éŸ³é¢‘ï¼ˆç§’ï¼‰
OUTPUT_FILE = "conversation_log.txt"
AUDIO_SAVE_DIR = "recordings"
MODEL = "whisper-1"


class AudioRecorder:
    def __init__(self):
        self.audio = pyaudio.PyAudio()
        self.stream = None
        self.frames = []
        self.is_recording = False
        self.last_submit_time = time.time()
        self.audio_counter = 1

        # åˆå§‹åŒ–ç›®å½•å’Œæ–‡ä»¶
        os.makedirs(AUDIO_SAVE_DIR, exist_ok=True)
        with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
            f.write(
                f"\n\n===== æ–°ä¼šè¯å¼€å§‹äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} =====\n"
            )

    def start_recording(self):
        """å¼€å§‹å½•éŸ³å¹¶è‡ªåŠ¨æäº¤"""
        self.is_recording = True
        self.stream = self.audio.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=SAMPLE_RATE,
            input=True,
            frames_per_buffer=CHUNK_SIZE,
        )
        print("ğŸ¤ éº¦å…‹é£å·²å¼€å¯ï¼Œå¼€å§‹è‡ªåŠ¨å½•éŸ³å’Œè½¬å½•...")

        while self.is_recording:
            # æŒç»­è¯»å–éŸ³é¢‘æ•°æ®
            data = self.stream.read(CHUNK_SIZE, exception_on_overflow=False)
            self.frames.append(data)

            # å®šæ—¶æ£€æŸ¥æ˜¯å¦åˆ°è¾¾æäº¤é—´éš”
            current_time = time.time()
            if current_time - self.last_submit_time >= SEGMENT_DURATION:
                self._submit_audio_segment()
                self.last_submit_time = current_time

            time.sleep(0.01)  # è½»å¾®å»¶è¿Ÿé¿å…CPUè¿‡è½½

    def _submit_audio_segment(self):
        """æäº¤å½“å‰éŸ³é¢‘ç‰‡æ®µåˆ°API"""
        if not self.frames:
            return

        # ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
        filename = os.path.join(AUDIO_SAVE_DIR, f"segment_{self.audio_counter}.wav")
        self.audio_counter += 1

        with wave.open(filename, "wb") as wf:
            wf.setnchannels(1)
            wf.setsampwidth(self.audio.get_sample_size(pyaudio.paInt16))
            wf.setframerate(SAMPLE_RATE)
            wf.writeframes(b"".join(self.frames))

        # é‡ç½®ç¼“å†²åŒº
        self.frames = []

        # åœ¨åå°çº¿ç¨‹ä¸­å¤„ç†APIè¯·æ±‚
        threading.Thread(
            target=self._transcribe_and_save, args=(filename,), daemon=True
        ).start()

    def _transcribe_and_save(self, filename: str):
        """è°ƒç”¨APIå¹¶ä¿å­˜ç»“æœ"""
        try:
            # è°ƒç”¨Whisper API
            url = "https://api.openai.com/v1/audio/transcriptions"
            headers = {"Authorization": f"Bearer {API_KEY}"}

            with open(filename, "rb") as audio_file:
                response = requests.post(
                    url,
                    headers=headers,
                    files={"file": audio_file},
                    data={"model": MODEL},
                    timeout=30,
                )

            if response.status_code == 200:
                result = response.json()
                text = result.get("text", "").strip()
                if text:
                    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    output = f"[{timestamp}] {text}"
                    print(f"\nğŸ”Š è¯†åˆ«ç»“æœ: {output}")

                    # ä¿å­˜åˆ°æ—¥å¿—æ–‡ä»¶
                    with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
                        f.write(output + "\n")
            else:
                print(f"APIé”™è¯¯: {response.status_code} - {response.text}")

        except Exception as e:
            print(f"è½¬å½•å¤±è´¥: {str(e)}")
        finally:
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(filename)
            except:
                pass

    def stop(self):
        """åœæ­¢å½•éŸ³å¹¶æäº¤æœ€åç‰‡æ®µ"""
        if self.is_recording:
            self.is_recording = False
            if self.stream:
                self.stream.stop_stream()
                self.stream.close()

            # æäº¤å‰©ä½™çš„éŸ³é¢‘æ•°æ®
            if self.frames:
                self._submit_audio_segment()

            print("â¹ï¸ å½•éŸ³å·²åœæ­¢")


def main():
    recorder = AudioRecorder()

    try:
        print("=" * 50)
        print("Whisper API å®æ—¶è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ")
        print(f"é‡‡æ ·ç‡: {SAMPLE_RATE}Hz | è‡ªåŠ¨æäº¤é—´éš”: {SEGMENT_DURATION}ç§’")
        print(f"éŸ³é¢‘ä¿å­˜ç›®å½•: {os.path.abspath(AUDIO_SAVE_DIR)}")
        print(f"æ–‡æœ¬è¾“å‡ºæ–‡ä»¶: {os.path.abspath(OUTPUT_FILE)}")
        print("=" * 50)
        print("ç¨‹åºå°†è‡ªåŠ¨å¼€å§‹å½•éŸ³ï¼ŒæŒ‰ Ctrl+C åœæ­¢...")

        # å¯åŠ¨å½•éŸ³
        recorder.start_recording()

    except KeyboardInterrupt:
        print("\næ¥æ”¶åˆ°åœæ­¢ä¿¡å·...")
    finally:
        recorder.stop()
        print(f"å¯¹è¯å·²ä¿å­˜è‡³: {OUTPUT_FILE}")
        print("ç¨‹åºé€€å‡º")


if __name__ == "__main__":
    main()

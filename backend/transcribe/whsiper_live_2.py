import os
import json
import requests
import time
import wave
import threading
import queue
import sounddevice as sd
import soundfile as sf
import numpy as np
from datetime import datetime
from dotenv import load_dotenv
import sys
from scipy.signal import resample_poly  # ä½¿ç”¨æ›´å¥½çš„é‡é‡‡æ ·æ–¹æ³•

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®å‚æ•°
API_KEY = os.getenv("OPENAI_API_KEY")
if not API_KEY:
    raise ValueError("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®OPENAI_API_KEY")

SAMPLE_RATE = 16000  # Whisperè¦æ±‚çš„é‡‡æ ·ç‡
CHUNK_SIZE = 1024    # æ¯æ¬¡è¯»å–çš„éŸ³é¢‘å—å¤§å°
SEGMENT_DURATION = 10.0  # æ¯5ç§’è‡ªåŠ¨æäº¤ä¸€æ¬¡éŸ³é¢‘ï¼ˆç§’ï¼‰
OUTPUT_FILE = "conversation_log.txt"
AUDIO_SAVE_DIR = "recordings"
MODEL = "whisper-1"

class SystemAudioRecorder:
    def __init__(self):
        self.is_recording = False
        self.last_submit_time = time.time()
        self.audio_counter = 1
        self.audio_queue = queue.Queue()
        self.current_frames = []
        self.device_id = None
        
        # åˆå§‹åŒ–ç›®å½•å’Œæ–‡ä»¶
        os.makedirs(AUDIO_SAVE_DIR, exist_ok=True)
        with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
            f.write(f"\n\n===== æ–°ä¼šè¯å¼€å§‹äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} =====\n")
        
        # æŸ¥æ‰¾åˆé€‚çš„æ‰¬å£°å™¨è®¾å¤‡
        self._find_speaker_device()

    def _find_speaker_device(self):
        """æŸ¥æ‰¾ç³»ç»Ÿæ‰¬å£°å™¨è®¾å¤‡"""
        print("å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡:")
        devices = sd.query_devices()
        hostapis = sd.query_hostapis()
        
        for i, dev in enumerate(devices):
            # è·å–ä¸»æœºAPIåç§°
            hostapi_name = hostapis[dev['hostapi']]['name'] if dev['hostapi'] < len(hostapis) else "Unknown"
            
            print(f"{i}: {dev['name']} (è¾“å…¥é€šé“: {dev['max_input_channels']}, è¾“å‡ºé€šé“: {dev['max_output_channels']}, API: {hostapi_name})")
            
            # æ ¹æ®æ“ä½œç³»ç»Ÿå’Œè®¾å¤‡åç§°é€‰æ‹©è®¾å¤‡
            if sys.platform == "win32":
                # Windows: å¯»æ‰¾"ç«‹ä½“å£°æ··éŸ³"æˆ–ç±»ä¼¼è®¾å¤‡
                if ("mix" in dev["name"].lower() or 
                    "stereo" in dev["name"].lower() or 
                    "æ··éŸ³" in dev["name"]):
                    if dev["max_input_channels"] > 0:
                        self.device_id = i
                        print(f"âœ… æ‰¾åˆ°æ‰¬å£°å™¨è®¾å¤‡: {dev['name']}")
                        return
            elif sys.platform == "darwin":
                # macOS: ä½¿ç”¨Soundfloweræˆ–BlackHole
                if "blackhole" in dev["name"].lower() or "soundflower" in dev["name"].lower():
                    if dev["max_input_channels"] > 0:
                        self.device_id = i
                        print(f"âœ… æ‰¾åˆ°æ‰¬å£°å™¨è®¾å¤‡: {dev['name']}")
                        return
            elif sys.platform.startswith("linux"):
                # Linux: ä½¿ç”¨pulseçš„monitorè®¾å¤‡
                if "monitor" in dev["name"].lower():
                    if dev["max_input_channels"] > 0:
                        self.device_id = i
                        print(f"âœ… æ‰¾åˆ°æ‰¬å£°å™¨è®¾å¤‡: {dev['name']}")
                        return
        
        # å¦‚æœæ²¡æ‰¾åˆ°ä¸“ç”¨è®¾å¤‡ï¼Œä½¿ç”¨é»˜è®¤è¾“å…¥è®¾å¤‡
        print("âš ï¸ æœªæ‰¾åˆ°ä¸“ç”¨æ‰¬å£°å™¨è®¾å¤‡ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤è¾“å…¥è®¾å¤‡")
        try:
            self.device_id = sd.default.device[0]  # é»˜è®¤è¾“å…¥è®¾å¤‡
            print(f"ä½¿ç”¨é»˜è®¤è¾“å…¥è®¾å¤‡: {devices[self.device_id]['name']}")
        except:
            print("æ— æ³•è·å–é»˜è®¤è¾“å…¥è®¾å¤‡")
            self.device_id = None
        
        if self.device_id is None:
            raise RuntimeError("æ‰¾ä¸åˆ°å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡")

    def _audio_callback(self, indata, frames, time, status):
        """éŸ³é¢‘æ•°æ®å›è°ƒå‡½æ•°"""
        if status:
            print(f"éŸ³é¢‘æµçŠ¶æ€: {status}")
        
        # å°†éŸ³é¢‘æ•°æ®æ”¾å…¥é˜Ÿåˆ—
        self.audio_queue.put(indata.copy())

    def start_recording(self):
        """å¼€å§‹å½•åˆ¶ç³»ç»ŸéŸ³é¢‘å¹¶è‡ªåŠ¨æäº¤"""
        self.is_recording = True
        
        # è·å–è®¾å¤‡ä¿¡æ¯
        device_info = sd.query_devices(self.device_id)
        print(f"è®¾å¤‡ä¿¡æ¯: {device_info}")
        
        # ä½¿ç”¨è®¾å¤‡æ”¯æŒçš„æœ€é«˜é‡‡æ ·ç‡ï¼Œä½†ä¸è¶…è¿‡48000
        sample_rate = int(min(device_info['default_samplerate'], 48000))
        channels = min(2, device_info['max_input_channels'])
        print(f"ä½¿ç”¨é‡‡æ ·ç‡: {sample_rate}Hz, é€šé“æ•°: {channels}")
        
        # å¼€å§‹å½•åˆ¶
        self.stream = sd.InputStream(
            device=self.device_id,
            channels=channels,
            samplerate=sample_rate,
            blocksize=CHUNK_SIZE,
            callback=self._audio_callback
        )
        
        self.stream.start()
        print(f"ğŸ”Š å¼€å§‹å½•åˆ¶ç³»ç»ŸéŸ³é¢‘")
        
        try:
            while self.is_recording:
                # ä»é˜Ÿåˆ—è·å–éŸ³é¢‘æ•°æ®
                try:
                    audio_data = self.audio_queue.get(timeout=0.1)
                    self.current_frames.append(audio_data)
                except queue.Empty:
                    pass
                
                # å®šæ—¶æ£€æŸ¥æ˜¯å¦åˆ°è¾¾æäº¤é—´éš”
                current_time = time.time()
                if current_time - self.last_submit_time >= SEGMENT_DURATION:
                    self._submit_audio_segment(sample_rate, channels)
                    self.last_submit_time = current_time
        except KeyboardInterrupt:
            print("å½•åˆ¶è¢«ä¸­æ–­")
        except Exception as e:
            print(f"å½•åˆ¶é”™è¯¯: {str(e)}")
        finally:
            self.stream.stop()
            self.stream.close()
            # æäº¤å‰©ä½™çš„éŸ³é¢‘æ•°æ®
            if self.current_frames:
                self._submit_audio_segment(sample_rate, channels)
            print("â¹ï¸ å½•éŸ³å·²åœæ­¢")

    def _submit_audio_segment(self, sample_rate: int, channels: int):
        """æäº¤å½“å‰éŸ³é¢‘ç‰‡æ®µåˆ°API"""
        if not self.current_frames:
            return
            
        # ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
        filename = os.path.join(AUDIO_SAVE_DIR, f"segment_{self.audio_counter}.wav")
        self.audio_counter += 1
        
        try:
            # åˆå¹¶æ‰€æœ‰éŸ³é¢‘å¸§
            audio_data = np.vstack(self.current_frames)
            
            # è½¬æ¢ä¸ºå•å£°é“
            if channels > 1:
                audio_data = np.mean(audio_data, axis=1)
            
            # å¦‚æœé‡‡æ ·ç‡ä¸æ˜¯16000ï¼Œè¿›è¡Œé‡é‡‡æ ·
            if sample_rate != SAMPLE_RATE:
                # è®¡ç®—é‡é‡‡æ ·æ¯”ä¾‹
                gcd = np.gcd(sample_rate, SAMPLE_RATE)
                up = SAMPLE_RATE // gcd
                down = sample_rate // gcd
                
                # ä½¿ç”¨æ›´å¯é çš„é‡é‡‡æ ·æ–¹æ³•
                audio_data = resample_poly(audio_data, up, down)
            
            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            sf.write(filename, audio_data, SAMPLE_RATE)
            print(f"âœ… éŸ³é¢‘ç‰‡æ®µä¿å­˜æˆåŠŸ: {filename}")
        except Exception as e:
            print(f"ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}")
            return
        finally:
            # é‡ç½®ç¼“å†²åŒº
            self.current_frames = []
        
        # åœ¨åå°çº¿ç¨‹ä¸­å¤„ç†APIè¯·æ±‚
        threading.Thread(
            target=self._transcribe_and_save,
            args=(filename,),
            daemon=True
        ).start()

    def _transcribe_and_save(self, filename: str):
        """è°ƒç”¨APIå¹¶ä¿å­˜ç»“æœ"""
        try:
            # è°ƒç”¨Whisper API
            url = "https://api.openai.com/v1/audio/transcriptions"
            headers = {"Authorization": f"Bearer {API_KEY}"}
            
            with open(filename, "rb") as audio_file:
                response = requests.post(
                    url,
                    headers=headers,
                    files={"file": audio_file},
                    data={"model": MODEL},
                    timeout=30
                )
            
            if response.status_code == 200:
                result = response.json()
                text = result.get("text", "").strip()
                if text:
                    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    output = f"[{timestamp}] {text}"
                    print(f"\nğŸ”Š è¯†åˆ«ç»“æœ: {output}")
                    
                    # ä¿å­˜åˆ°æ—¥å¿—æ–‡ä»¶
                    with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
                        f.write(output + "\n")
            else:
                print(f"APIé”™è¯¯: {response.status_code} - {response.text}")
                
        except Exception as e:
            print(f"è½¬å½•å¤±è´¥: {str(e)}")
        finally:
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(filename)
            except:
                pass

def main():
    recorder = SystemAudioRecorder()
    
    try:
        print("="*50)
        print("Whisper API ç³»ç»ŸéŸ³é¢‘å®æ—¶è¯†åˆ«ç³»ç»Ÿ")
        print(f"é‡‡æ ·ç‡: {SAMPLE_RATE}Hz | è‡ªåŠ¨æäº¤é—´éš”: {SEGMENT_DURATION}ç§’")
        print(f"éŸ³é¢‘ä¿å­˜ç›®å½•: {os.path.abspath(AUDIO_SAVE_DIR)}")
        print(f"æ–‡æœ¬è¾“å‡ºæ–‡ä»¶: {os.path.abspath(OUTPUT_FILE)}")
        print("="*50)
        print("ç¨‹åºå°†å¼€å§‹å½•åˆ¶ç³»ç»ŸéŸ³é¢‘ï¼ŒæŒ‰ Ctrl+C åœæ­¢...")
        
        # å¯åŠ¨å½•éŸ³
        recorder.start_recording()
        
    except KeyboardInterrupt:
        print("\næ¥æ”¶åˆ°åœæ­¢ä¿¡å·...")
    except Exception as e:
        print(f"ç¨‹åºé”™è¯¯: {str(e)}")
    finally:
        print(f"è½¬å½•ç»“æœå·²ä¿å­˜è‡³: {OUTPUT_FILE}")
        print("ç¨‹åºé€€å‡º")

if __name__ == "__main__":
    main()
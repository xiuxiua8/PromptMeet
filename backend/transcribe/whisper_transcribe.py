import os
import json
import requests
import time
import math
import threading
from typing import Dict, Optional, List, Tuple
from pydub import AudioSegment
import tempfile
from queue import Queue

class AudioTranscriber:
    """æ”¯æŒå¤šçº¿ç¨‹åˆ†å—è½¬å†™çš„è¯­éŸ³è½¬å†™å·¥å…·ç±»ï¼ˆå«åˆ†å—ç‹¬ç«‹è®¡æ—¶ï¼‰"""
    
    def __init__(self, api_key: Optional[str] = None, chunk_size: int = 300, max_workers: int = 4):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("æœªè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        self.chunk_size = chunk_size
        self.max_workers = max_workers
        self.result_queue = Queue()
        self.lock = threading.Lock()
        self.completed_chunks = 0
        self.chunk_times = {}  # å­˜å‚¨æ¯ä¸ªåˆ†å—çš„è€—æ—¶ {chunk_name: time}
    
    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        if seconds < 1:
            return f"{seconds*1000:.0f}æ¯«ç§’"
        return f"{seconds:.2f}ç§’"

    def _split_audio(self, file_path: str) -> List[Tuple[str, float]]:
        """åˆ†å‰²éŸ³é¢‘æ–‡ä»¶ï¼ˆæ˜¾ç¤ºæ¯ä¸ªåˆ†å—æ—¶é—´èŒƒå›´ï¼‰"""
        audio = AudioSegment.from_file(file_path)
        total_duration_sec = len(audio) / 1000
        
        if total_duration_sec <= self.chunk_size:
            print(f"ğŸ” ç›´æ¥å¤„ç†å®Œæ•´æ–‡ä»¶ | æ—¶é•¿: {self._format_time(total_duration_sec)}")
            return [(file_path, 0.0)]

        chunks = []
        temp_dir = tempfile.mkdtemp()
        num_chunks = math.ceil(total_duration_sec / self.chunk_size)
        
        for i in range(num_chunks):
            start_sec = i * self.chunk_size
            end_sec = min((i + 1) * self.chunk_size, total_duration_sec)
            chunk = audio[start_sec*1000 : end_sec*1000]
            chunk_path = os.path.join(temp_dir, f"chunk_{i+1}.wav")
            chunk.export(chunk_path, format="wav")
            chunks.append((chunk_path, start_sec))
            print(f"âœ‚ï¸ åˆ†å— {i+1}/{num_chunks} | æ—¶é—´èŒƒå›´: {start_sec:.1f}s-{end_sec:.1f}s")
        
        return chunks
    
    def _transcribe_chunk(self, chunk_path: str, offset: float, model: str, keep_words: bool):
        """è½¬å†™å•ä¸ªåˆ†å—ï¼ˆå¼ºåˆ¶æ˜¾ç¤ºæ¯ä¸ªåˆ†å—è€—æ—¶ï¼‰"""
        chunk_name = os.path.basename(chunk_path)
        start_time = time.time()
        
        try:
            url = "https://api.openai.com/v1/audio/transcriptions"
            headers = {"Authorization": f"Bearer {self.api_key}"}
            with open(chunk_path, "rb") as audio_file:
                files = {"file": (chunk_name, audio_file, "audio/wav")}
                data = {"model": model, "response_format": "verbose_json"}
                if keep_words:
                    data["timestamp_granularities[]"] = ["word"]
                
                response = requests.post(url, headers=headers, data=data, files=files, timeout=120)
                elapsed = time.time() - start_time
                
                if response.status_code == 200:
                    result = response.json()
                    # è°ƒæ•´æ—¶é—´æˆ³åç§»
                    for segment in result.get("segments", []):
                        segment["start"] += offset
                        segment["end"] += offset
                        if "words" in segment:
                            for word in segment["words"]:
                                word["start"] += offset
                                word["end"] += offset
                    
                    with self.lock:
                        self.result_queue.put(result)
                        self.completed_chunks += 1
                        self.chunk_times[chunk_name] = elapsed
                        print(
                            f"âœ… {chunk_name} å®Œæˆ | "
                            f"è€—æ—¶: {self._format_time(elapsed)} | "
                            f"è¿›åº¦: {self.completed_chunks}/{self.total_chunks}"
                        )
                else:
                    print(f"âŒ {chunk_name} å¤±è´¥ | çŠ¶æ€ç : {response.status_code}")
        except Exception as e:
            print(f"âŒ {chunk_name} å¼‚å¸¸ | {type(e).__name__}: {str(e)}")
        finally:
            try:
                os.remove(chunk_path)
            except:
                pass
    
    def transcribe_audio(self, file_path: str, model: str = "whisper-1", keep_words: bool = False) -> Optional[Dict]:
        """æ‰§è¡Œå¤šçº¿ç¨‹è½¬å†™ï¼ˆæ˜¾ç¤ºæ¯ä¸ªåˆ†å—ç‹¬ç«‹è€—æ—¶ï¼‰"""
        global_start = time.time()
        chunks = self._split_audio(file_path)
        self.total_chunks = len(chunks)
        self.completed_chunks = 0
        self.chunk_times.clear()
        
        if not chunks:
            return None

        print(
            f"\nâ±ï¸ å¼€å§‹è½¬å†™ | åˆ†å—æ•°: {self.total_chunks} | "
            f"çº¿ç¨‹æ•°: {self.max_workers} | "
            f"é¢„ä¼°æ€»æ—¶é•¿: {self._format_time(self.total_chunks * 2)} (åŸºäº2ç§’/åˆ†å—é¢„ä¼°)"
        )

        # å¯åŠ¨è½¬å†™çº¿ç¨‹
        threads = []
        for chunk_path, offset in chunks:
            while threading.active_count() > self.max_workers:
                time.sleep(0.1)
            
            t = threading.Thread(
                target=self._transcribe_chunk,
                args=(chunk_path, offset, model, keep_words),
                daemon=True
            )
            t.start()
            threads.append(t)

        # ç­‰å¾…å®Œæˆ
        for t in threads:
            t.join()
        
        # æ‰“å°è¯¦ç»†è€—æ—¶æŠ¥å‘Š
        total_elapsed = time.time() - global_start
        print("\nğŸ“Š åˆ†å—è€—æ—¶ç»Ÿè®¡:")
        for chunk, elapsed in self.chunk_times.items():
            print(f"  - {chunk}: {self._format_time(elapsed)}")
        
        print(
            f"\nâœ… å…¨éƒ¨å®Œæˆ | æ€»è€—æ—¶: {self._format_time(total_elapsed)} | "
            f"å®é™…é€Ÿåº¦: {total_elapsed/self.total_chunks:.2f}ç§’/åˆ†å—"
        )
        return self._merge_results()
    

    def _merge_results(self) -> Dict:
        """åˆå¹¶æ‰€æœ‰åˆ†å—ç»“æœ"""
        merged = {"text": "", "language": None, "duration": 0.0, "segments": []}
        
        while not self.result_queue.empty():
            result = self.result_queue.get()
            if not merged["language"] and "language" in result:
                merged["language"] = result["language"]
            
            merged["text"] += result.get("text", "") + " "
            merged["duration"] = max(merged["duration"], result.get("duration", 0.0))
            merged["segments"].extend(result.get("segments", []))
        
        merged["segments"].sort(key=lambda x: x["start"])
        merged["text"] = merged["text"].strip()
        return merged
    
    def save_results(self, data: Dict, filename: str) -> bool:
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            return True
        except Exception as e:
            print(f"âŒ ç»“æœä¿å­˜å¤±è´¥: {str(e)}")
            return False